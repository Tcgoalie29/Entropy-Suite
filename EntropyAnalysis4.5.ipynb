{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiscale Entropy Analysis\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "from tqdm.notebook import tqdm\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.colors import sample_colorscale\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "try:\n",
    "    import mne\n",
    "except ImportError:\n",
    "    print(\"mne library not found. Please install it for EEG data processing.\")\n",
    "\n",
    "try:\n",
    "    import EntropyHub\n",
    "    Mobj = EntropyHub.MSobject('FuzzEn')\n",
    "except ImportError:\n",
    "    print(\"EntropyHub library not found. Please install it for entropy analysis.\")\n",
    "\n",
    "try:\n",
    "    import utilities\n",
    "except ImportError:\n",
    "    print(\"Utilities module not found. Check if the file is in the project directory.\")\n",
    "\n",
    "# Matplotlib settings for GUI compatibility\n",
    "plt.rcParams.update({'font.size': 12, 'interactive': True})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Set folder path to data, this will produce a list of subjects based on the files in this folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_subject_list(folder_path):\n",
    "    file_list = os.listdir(folder_path)\n",
    "    # Remove file extension and get unique subject names\n",
    "    subject_list = [os.path.splitext(file)[0] for file in file_list if file.endswith('.csv')]\n",
    "    return np.array(subject_list)\n",
    "\n",
    "# Replace with your folder path or use a GUI element to get the path\n",
    "folder_path = '/Users/tannercreel/Desktop/Test'  # This will be set through the GUI\n",
    "subject_list = get_subject_list(folder_path)\n",
    "print(subject_list)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load data for one subject of choice. Specify the index of the subject from `subject_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subject_idx = 1\n",
    "dpath = '/Users/tannercreel/Desktop/Test/{}.csv'.format(subject_list[subject_idx]) # Replace with your folder path up to \"/{.csv}\"\n",
    "data = pd.read_csv(dpath)\n",
    "data = data.iloc[:,1:] # remove the first column because that column is the timestamps column\n",
    "ch_names = data.columns\n",
    "sfreq = 256\n",
    "time = np.linspace(0, data.shape[0]/sfreq, data.shape[0])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Trim data to only include the first 30sec of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_data_length = np.arange(0, 30*sfreq) # Trim to desired length in seconds\n",
    "data = data.iloc[trimmed_data_length,:]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Compute Sample Entropy on a given channel of the data at multiple scales and Complexity Index (Single-subject single-channel analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the channel for analysis\n",
    "target_channel = 'Alpha_AF7'\n",
    "scales = 20\n",
    "scales_list = np.arange(1, scales + 1)\n",
    "\n",
    "# Initialize empty dataframe to store results\n",
    "entropy_df = pd.DataFrame(columns=[\"channel\", \"entropy\", \"complexity_index\"])\n",
    "\n",
    "# Compute MSE and CI for the specified channel\n",
    "Msx, CI = EntropyHub.MSEn(data[target_channel].values, Mobj, Scales=scales)\n",
    "\n",
    "# Append results to dataframe using concat\n",
    "new_row = pd.DataFrame({\"channel\": [target_channel], \"entropy\": [Msx], \"complexity_index\": [CI]})\n",
    "entropy_df = pd.concat([entropy_df, new_row], ignore_index=True)\n",
    "\n",
    "# Create subplots with two columns\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"MSE\", \"Complexity Index\"))\n",
    "\n",
    "# Add line graph for MSE\n",
    "fig.add_trace(go.Scatter(x=scales_list, y=Msx, mode='lines+markers', line=dict(color='black'),\n",
    "                         marker=dict(color='black', size=8), name='MSE'), row=1, col=1)\n",
    "\n",
    "# Add bar graph for Complexity Index\n",
    "fig.add_trace(go.Bar(x=[target_channel], y=[CI], marker=dict(color='blue'), name='Complexity Index'), row=1, col=2)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(template='simple_white', width=1200, height=600, font=dict(size=20),\n",
    "                  xaxis_title='Scales', title_text=f\"Analysis for {target_channel}\")\n",
    "\n",
    "# Set x-axis tickvals and ticktext for the bar graph\n",
    "fig.update_xaxes(tickvals=[target_channel], ticktext=[target_channel], row=1, col=2)\n",
    "\n",
    "# Show plot\n",
    "fig.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Compute Multiscale Entropy (MSE) for each channel, plot all the channels, and the average MSE across channels (Single-subject multichannel analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = 20\n",
    "scales_list = np.arange(1, scales + 1)\n",
    "\n",
    "mse_across_channels_df = pd.DataFrame(columns=ch_names)\n",
    "ci_df = pd.DataFrame(columns=['Channel', 'CI'])\n",
    "\n",
    "for ch in tqdm(ch_names):\n",
    "    ch_data = data[ch].values\n",
    "\n",
    "    Msx, CI = EntropyHub.MSEn(ch_data, Mobj, Scales=scales)\n",
    "\n",
    "    mse_series = pd.Series(Msx, name=ch)\n",
    "    mse_across_channels_df[ch] = mse_series\n",
    "    ci_df = pd.concat([ci_df, pd.DataFrame({'Channel': [ch], 'CI': [CI]})], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization code\n",
    "fig = make_subplots(cols=2, column_widths=[0.2, 0.4], horizontal_spacing=0.08)\n",
    "colorscale = 'cividis'\n",
    "colors = sample_colorscale(colorscale, np.linspace(0, 1, len(ch_names)), low=0.0, high=0.9, colortype='rgb')\n",
    "\n",
    "for i, ch in enumerate(ch_names):\n",
    "    mse_vals = mse_across_channels_df[ch].values\n",
    "    fig.add_trace(go.Scattergl(x=scales_list, y=mse_vals, mode='lines+markers', line=dict(color=colors[i]),\n",
    "                               marker=dict(color=colors[i], size=8), name=ch), row=1, col=1)\n",
    "\n",
    "mean_mse = mse_across_channels_df.mean(axis=1).values\n",
    "sem_mse = mse_across_channels_df.sem(axis=1).values\n",
    "fig.add_trace(go.Scattergl(x=scales_list, y=mean_mse, error_y=dict(type='data', array=sem_mse, visible=True),\n",
    "                           mode='lines+markers', line=dict(color='brown', width=6),\n",
    "                           marker=dict(color='brown', size=12), name='Average'), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Bar(x=ci_df['Channel'], y=ci_df['CI'], marker=dict(color=colors, line=dict(color='black', width=1)), showlegend=False), row=1, col=2)\n",
    "\n",
    "fig.update_layout(template='simple_white', width=1800, height=600, font=dict(size=20),\n",
    "                  xaxis_title='Scales', yaxis_title='Sample Entropy', title_text=subject_list[subject_idx])\n",
    "fig.update_yaxes(title_text='Complexity Index', row=1, col=2)\n",
    "fig.show()\n",
    "fig.write_html('./{}_EntropyAcrossChannels.html'.format(subject_list[subject_idx]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 7. Compute MSE across all subjects in a given group (Group-level multichannel average)\n",
    "- #### a. Load all data for all subjects in `folder_path` and put in a dictionary object\n",
    "- #### b. Compute MSE for each channel, get the average MSE for each subject, and save the MSE per scale in a df\n",
    "- #### c. Plot the MSE values across each subject and the average across subjects\n",
    "- #### z. MSE across all channels and across all subjects in folder_path in wide format CSV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Load all data for all subjects in `folder_path` and put in a dictionary object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_dict = {} # initialize an empty dictionary to which each subject's data will be added\n",
    "trimmed_data_length = np.arange(0, 30*sfreq) # define the length of data to trim down to\n",
    "\n",
    "for subject_name in tqdm(subject_list):\n",
    "    dpath = '/Users/tannercreel/Desktop/Dissertation/Python_Projects/Cannabis Complexity/Frequent_Users/{}.csv'.format(subject_name)\n",
    "    data = pd.read_csv(dpath)\n",
    "    data = data.iloc[:,1:] # remove the first column because that column is the timestamps column\n",
    "\n",
    "    data = data.iloc[trimmed_data_length,:] # trim the data to just the first 30sec\n",
    "\n",
    "    all_data_dict[subject_name] = data # add the current subject's data to the dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Compute MSE for each channel, get the average MSE for each subject, and save the MSE per scale in a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = 20\n",
    "scales_list = np.arange(1, scales+1)\n",
    "chs_to_exclude = ['VEOG', 'HEOG', 'LeftMast', 'RightMast'] # define any channels to exclude\n",
    "\n",
    "# initialize empty dataframes to which the data will be added in the for loop\n",
    "mse_across_subjects_df = pd.DataFrame(columns=['Subject','Scale','Entropy'])\n",
    "ci_across_subjects_df  = pd.DataFrame(columns=['Subject','CI'])\n",
    "\n",
    "for subject_name in tqdm(subject_list):\n",
    "    data = all_data_dict[subject_name]\n",
    "    # Apply the boolean indexer to columns\n",
    "    data = data.loc[:, [ch not in chs_to_exclude for ch in data.columns]]\n",
    "\n",
    "    mean_eeg = data.mean(axis=1).values  # compute mean eeg trace\n",
    "    Msx, CI = EntropyHub.MSEn(mean_eeg, Mobj, Scales=scales)  # compute entropy across scales and complexity index\n",
    "\n",
    "    # add the current subject's data to the overall dataframes\n",
    "    subject_mse_df = pd.DataFrame({'Subject':subject_name, 'Scale':scales_list, 'Entropy':Msx})\n",
    "    mse_across_subjects_df = mse_across_subjects_df.append(subject_mse_df)\n",
    "    ci_across_subjects_df = ci_across_subjects_df.append(pd.Series({'Subject':subject_name, 'CI':CI}), ignore_index=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Plot the average MSE values across each subject and the average MSE values across all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# compute mean and standard error across subjects for MSE\n",
    "avg_mse_across_subjects = mse_across_subjects_df.groupby(['Scale']).mean().reset_index()['Entropy'].values\n",
    "sem_mse_across_subjects = mse_across_subjects_df.groupby(['Scale']).sem().reset_index()['Entropy'].values\n",
    "\n",
    "# plot each subject's data\n",
    "for subject_name in mse_across_subjects_df['Subject'].unique():\n",
    "    subject_data = mse_across_subjects_df[mse_across_subjects_df['Subject'] == subject_name]\n",
    "\n",
    "    fig.add_trace(go.Scattergl(x=subject_data['Scale'].values, y=subject_data['Entropy'].values, mode='lines+markers', line=dict(color='slategrey'),\n",
    "                               marker=dict(color='slategrey', size=8), name=subject_name))\n",
    "\n",
    "# add line for average across subjects\n",
    "fig.add_trace(go.Scattergl(x=scales_list, y=avg_mse_across_subjects, error_y=dict(type='data', array=sem_mse_across_subjects, visible=True),\n",
    "                           mode='lines+markers', line=dict(color='black', width=6),\n",
    "                           marker=dict(color='black', size=12), name='Average'))\n",
    "\n",
    "fig.update_layout(template='simple_white', width=1000, height=600, font=dict(size=20),\n",
    "                  xaxis_title='Scales', yaxis_title='Sample Entropy')\n",
    "fig.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### z. Compute MSE across all channels and all subjects in folder_path in wide format CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE Wide_Format \n",
    "\n",
    "# Initialize key parameters\n",
    "trim_length = 30  # Length of data segments to trim (in seconds)\n",
    "group_name = 'Frequent_Users'  # Group name for the analysis\n",
    "scales = 20  # Number of scales for Multiscale Entropy (MSE) calculation\n",
    "scales_list = np.arange(1, scales + 1)  # List of scales from 1 to the specified number of scales\n",
    "sfreq = 1000  # Sampling frequency of the data (in Hz)\n",
    "\n",
    "# Initialize column names for the DataFrame\n",
    "col_names = [\"subject\", \"channel\"]\n",
    "col_names.extend([\"scale\" + str(scale) for scale in scales_list])\n",
    "\n",
    "# Initialize DataFrames to store entropy and complexity index (CI) results\n",
    "entropy_allsubjects_df = pd.DataFrame()\n",
    "ci_allsubjects_df = pd.DataFrame(columns=[\"subject\", \"channel\", \"complexity_index\"])\n",
    "\n",
    "# Loop through each subject (example uses the first subject for demonstration)\n",
    "for i, subject in enumerate(subject_list[:1]):\n",
    "    # Define the path to the subject's data file\n",
    "    dpath = '/Users/tannercreel/Desktop/Dissertation/Python_Projects/Cannabis Complexity/{}/{}.csv'.format(group_name, subject)\n",
    "\n",
    "    # Read the data from the CSV file\n",
    "    data = pd.read_csv(dpath)\n",
    "    \n",
    "    # Trim the data to the specified length\n",
    "    trimmed_data_length = np.arange(0, trim_length * sfreq)\n",
    "    data = data.iloc[trimmed_data_length, :]\n",
    "    \n",
    "    # Get the channel names from the data\n",
    "    ch_names = data.columns\n",
    "\n",
    "    # Initialize a dictionary to store entropy values for each channel\n",
    "    channel_entropy_dict = {\"subject\": subject}\n",
    "    \n",
    "    # Calculate MSE and CI for each channel\n",
    "    for ch in ch_names:\n",
    "        Msx, CI = EntropyHub.MSEn(data[ch].values, Mobj, Scales=scales)\n",
    "        \n",
    "        # Update the dictionary with MSE values for each scale\n",
    "        channel_entropy_dict.update({scale: entropy for scale, entropy in zip([\"{}_scale\".format(ch) + str(scale) for scale in scales_list], Msx)})\n",
    "        \n",
    "        # Append the complexity index to the CI DataFrame\n",
    "        ci_allsubjects_df = ci_allsubjects_df.append(pd.Series({\"subject\": subject,\n",
    "                                                                \"channel\": ch,\n",
    "                                                                \"complexity_index\": CI}), ignore_index=True)\n",
    "    # Append the entropy values to the entropy DataFrame\n",
    "    entropy_allsubjects_df = entropy_allsubjects_df.append(channel_entropy_dict, ignore_index=True)\n",
    "    \n",
    "    # Print a completion message for the subject\n",
    "    print(\"{} has been completed\".format(subject))\n",
    "\n",
    "# Add metadata columns to the DataFrames\n",
    "entropy_allsubjects_df[\"group\"] = group_name\n",
    "ci_allsubjects_df[\"group\"] = group_name\n",
    "entropy_allsubjects_df[\"trim_length_seconds\"] = trim_length\n",
    "ci_allsubjects_df[\"trim_length_seconds\"] = trim_length\n",
    "\n",
    "# Optional: Save the DataFrames to CSV files \n",
    "# entropy_allsubjects_df.to_csv(\"/Users/tannercreel/Desktop/Dissertation/Cannabis-MSE/ProcessedData/MSE_All_Groups/MSE_{}.csv\".format(group_name))\n",
    "# ci_allsubjects_df.to_csv(\"/Users/tannercreel/Desktop/Dissertation/Cannabis-MSE/ProcessedData/MSE_All_Groups/CI_{}.csv\".format(group_name))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Compute MSE and Complexity Index for a specific channel across all subjects in a given group (Group-level single-channel analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the EEG data files are stored\n",
    "data_directory = '/Users/tannercreel/Desktop/Dissertation/Python_Projects/Cannabis Complexity/Non_Users'\n",
    "\n",
    "# Generate a list of subject names based on the CSV files in the directory\n",
    "subject_list = [os.path.splitext(file)[0] for file in os.listdir(data_directory) if file.endswith('.csv')]\n",
    "\n",
    "# Initialize variables\n",
    "all_data_dict = {}\n",
    "trimmed_data_length = np.arange(0, 30*sfreq)\n",
    "scales = 20\n",
    "scales_list = np.arange(1, scales+1)\n",
    "target_channel = 'FP2'  # Specify the target channel\n",
    "\n",
    "# Loop through each subject and store their data\n",
    "for subject_name in tqdm(subject_list):\n",
    "    dpath = f'{data_directory}/{subject_name}.csv'\n",
    "    data = pd.read_csv(dpath)\n",
    "    data = data.iloc[:,1:]  # Remove the first column (timestamps)\n",
    "    data = data.iloc[trimmed_data_length,:]  # Trim to the first 30sec\n",
    "    all_data_dict[subject_name] = data \n",
    "\n",
    "# Initialize DataFrame for MSE and CI values\n",
    "mse_single_channel_df = pd.DataFrame(columns=['Subject', 'Scale', 'Entropy'])\n",
    "ci_single_channel_df = pd.DataFrame(columns=['Subject', 'CI'])\n",
    "\n",
    "# Loop through each subject and calculate MSE and CI for the target channel\n",
    "for subject_name in tqdm(subject_list):\n",
    "    data = all_data_dict[subject_name]\n",
    "    ch_data = data[target_channel].values  # Extract data for the target channel\n",
    "    Msx, CI = EntropyHub.MSEn(ch_data, Mobj, Scales=scales)  # Compute MSE and CI\n",
    "\n",
    "    # Store MSE values in the DataFrame\n",
    "    for scale, entropy in zip(scales_list, Msx):\n",
    "        mse_single_channel_df = mse_single_channel_df.append({\n",
    "            'Subject': subject_name,\n",
    "            'Scale': scale,\n",
    "            'Entropy': entropy\n",
    "        }, ignore_index=True)\n",
    "    \n",
    "    # Store CI value in the DataFrame\n",
    "    ci_single_channel_df = ci_single_channel_df.append({\n",
    "        'Subject': subject_name,\n",
    "        'CI': CI\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Plotting for MSE\n",
    "fig_mse = go.Figure()\n",
    "\n",
    "# Compute mean and standard error across subjects for MSE\n",
    "avg_mse = mse_single_channel_df.groupby(['Scale'])['Entropy'].mean().values\n",
    "sem_mse = mse_single_channel_df.groupby(['Scale'])['Entropy'].sem().values\n",
    "\n",
    "# Plot the data for each subject\n",
    "for subject_name in mse_single_channel_df['Subject'].unique():\n",
    "    subject_data = mse_single_channel_df[mse_single_channel_df['Subject'] == subject_name]\n",
    "    fig_mse.add_trace(go.Scattergl(x=subject_data['Scale'], y=subject_data['Entropy'],\n",
    "                                   mode='lines+markers', name=subject_name))\n",
    "\n",
    "# Add line for average across subjects\n",
    "fig_mse.add_trace(go.Scattergl(x=scales_list, y=avg_mse, error_y=dict(type='data', array=sem_mse, visible=True),\n",
    "                               mode='lines+markers', line=dict(color='black', width=6),\n",
    "                               marker=dict(color='black', size=12), name='Average'))\n",
    "\n",
    "fig_mse.update_layout(template='simple_white', width=1000, height=600, font=dict(size=20),\n",
    "                      xaxis_title='Scales', yaxis_title='Sample Entropy', title=f'Group-Level Single-Channel MSE for {target_channel}')\n",
    "fig_mse.show()\n",
    "\n",
    "# Plotting for CI (if needed)\n",
    "fig_ci = go.Figure()\n",
    "\n",
    "# Plot the data for CI\n",
    "for subject_name in ci_single_channel_df['Subject'].unique():\n",
    "    subject_ci = ci_single_channel_df[ci_single_channel_df['Subject'] == subject_name]['CI'].values[0]\n",
    "    fig_ci.add_trace(go.Bar(x=[subject_name], y=[subject_ci]))\n",
    "\n",
    "fig_ci.update_layout(template='simple_white', width=1000, height=600, font=dict(size=20),\n",
    "                     xaxis_title='Subject', yaxis_title='Complexity Index', title=f'Group-Level Single-Channel CI for {target_channel}')\n",
    "fig_ci.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
