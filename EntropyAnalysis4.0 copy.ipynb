{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiscale Entropy Analysis\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "from tqdm.notebook import tqdm\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.colors import sample_colorscale\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import mne\n",
    "except ImportError:\n",
    "    print(\"mne library not found. Please install it for EEG data processing.\")\n",
    "\n",
    "try:\n",
    "    import EntropyHub\n",
    "    Mobj = EntropyHub.MSobject('SampEn')\n",
    "except ImportError:\n",
    "    print(\"EntropyHub library not found. Please install it for entropy analysis.\")\n",
    "\n",
    "try:\n",
    "    import utilities\n",
    "except ImportError:\n",
    "    print(\"Utilities module not found. Check if the file is in the project directory.\")\n",
    "\n",
    "# Matplotlib settings for GUI compatibility\n",
    "plt.rcParams.update({'font.size': 12, 'interactive': True})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Set folder path to data, this will produce a list of subjects based on the files in this folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_subject_list(folder_path):\n",
    "    file_list = os.listdir(folder_path)\n",
    "    # Remove file extension and get unique subject names\n",
    "    subject_list = [os.path.splitext(file)[0] for file in file_list if file.endswith('.csv')]\n",
    "    return np.array(subject_list)\n",
    "\n",
    "# Replace with your folder path or use a GUI element to get the path\n",
    "folder_path = '/Users/tannercreel/Desktop/Dissertation/Cannabis-MSE/ProcessedData copy/Low_Frequency Users'  # This will be set through the GUI\n",
    "subject_list = get_subject_list(folder_path)\n",
    "print(subject_list)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load data for one subject of choice. Specify the index of the subject from `subject_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_subject_data(folder_path, subject_name, sfreq):\n",
    "    file_name = f\"{subject_name}_FilteredData.csv\" if '_FilteredData' not in subject_name else f\"{subject_name}.csv\"\n",
    "    dpath = os.path.join(folder_path, file_name)\n",
    "\n",
    "    if not os.path.exists(dpath):\n",
    "        raise FileNotFoundError(f\"No such file: {dpath}\")\n",
    "\n",
    "    data = pd.read_csv(dpath)\n",
    "    if data.shape[1] <= 1:\n",
    "        raise ValueError(\"Data format error: Expected more than one column.\")\n",
    "\n",
    "    data = data.iloc[:, 1:]  # Remove the first column (assumed timestamps)\n",
    "    ch_names = data.columns\n",
    "    time = np.linspace(0, len(data) / sfreq, len(data))\n",
    "    return data, ch_names, time\n",
    "\n",
    "# Usage (Ensure that 'subject_list' and 'folder_path' are already defined)\n",
    "subject_idx = 0  # or any other mechanism to select a subject\n",
    "sfreq = 1000\n",
    "subject_name = subject_list[subject_idx]\n",
    "data, ch_names, time = load_subject_data(folder_path, subject_name, sfreq)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Trim data to only include the first 30sec of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_data(data, trim_length_sec, sfreq):\n",
    "    \"\"\"\n",
    "    Trims the data to the specified length in seconds.\n",
    "\n",
    "    :param data: DataFrame containing the EEG data.\n",
    "    :param trim_length_sec: Length in seconds to which the data is to be trimmed.\n",
    "    :param sfreq: Sampling frequency of the data.\n",
    "    :return: Trimmed DataFrame.\n",
    "    \"\"\"\n",
    "    trimmed_data_length = np.arange(0, trim_length_sec * sfreq)\n",
    "    return data.iloc[trimmed_data_length, :]\n",
    "\n",
    "# Example usage\n",
    "trimmed_data = trim_data(data, 30, sfreq)  # Trim to first 30 seconds\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Compute sample entropy on a given channel of the data at multiple scales\n",
    "- #### Specify which channel of the data to use\n",
    "- #### Specify the scales that the entropy should be computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = ch_names[0]\n",
    "scales = 20\n",
    "scales_list = np.arange(1, scales+1)\n",
    "entropy_df = pd.DataFrame(columns=[\"channel\", \"entropy\", \"complexity_index\"]) #Initialize empty data frame\n",
    "for ch in ch_names:\n",
    "    Msx, CI = EntropyHub.MSEn(data[ch].values, Mobj, Scales=scales)\n",
    "    entropy_df = entropy_df.append(pd.Series({\"channel\":ch,\n",
    "                                              \"entropy\":Msx,\n",
    "                                              \"complexity_index\":CI}),ignore_index=True) # recursive updating- defining a modified variable upon itself\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=scales_list, y=Msx, mode='lines+markers', line=dict(color='black'),\n",
    "                         marker=dict(color='black', size=8)))\n",
    "fig.update_layout(template='simple_white', width=600, height=400, font=dict(size=20),\n",
    "                  xaxis_title='Scales', yaxis_title='Sample Entropy')\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Compute MSE for each channel and plot all the channels and the average MSE across channels\n",
    "- #### Just like in section 5, specify the number of scales to include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = 20\n",
    "scales_list = np.arange(1, scales+1)\n",
    "\n",
    "mse_across_channels_df = pd.DataFrame(columns=ch_names)\n",
    "ci_df = pd.DataFrame(columns=['Channel','CI'])\n",
    "\n",
    "for ch in tqdm(ch_names):\n",
    "    ch_data = data[ch].values\n",
    "\n",
    "    Msx, CI = EntropyHub.MSEn(ch_data, Mobj, Scales=scales)\n",
    "\n",
    "    mse_series = pd.Series({ch:Msx})\n",
    "    mse_across_channels_df[ch] = Msx\n",
    "    ci_df = ci_df.append(pd.Series({'Channel':ch, 'CI':CI}), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(cols=2, column_widths=[0.2,0.4], horizontal_spacing=0.08)\n",
    "colorscale = 'cividis'\n",
    "colors = sample_colorscale(colorscale, np.linspace(0,1,len(ch_names)), low=0.0, high=0.9, colortype='rgb')\n",
    "\n",
    "for i, ch in enumerate(ch_names):\n",
    "    mse_vals = mse_across_channels_df[ch].values\n",
    "    fig.add_trace(go.Scattergl(x=scales_list, y=mse_vals, mode='lines+markers', line=dict(color=colors[i]),\n",
    "                               marker=dict(color=colors[i], size=8), name=ch), row=1, col=1)\n",
    "\n",
    "mean_mse = mse_across_channels_df.mean(axis=1).values\n",
    "sem_mse = mse_across_channels_df.sem(axis=1).values\n",
    "fig.add_trace(go.Scattergl(x=scales_list, y=mean_mse, error_y=dict(type='data', array=sem_mse, visible=True),\n",
    "                           mode='lines+markers', line=dict(color='brown', width=6),\n",
    "                           marker=dict(color='brown', size=12), name='Average'), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Bar(x=ci_df['Channel'], y=ci_df['CI'], marker=dict(color=colors, line=dict(color='black', width=1)), showlegend=False), row=1, col=2)\n",
    "\n",
    "fig.update_layout(template='simple_white', width=1800, height=600, font=dict(size=20),\n",
    "                  xaxis_title='Scales', yaxis_title='Sample Entropy', title_text=subject_list[subject_idx])\n",
    "fig.update_yaxes(title_text='Complexity Index', row=1, col=2)\n",
    "fig.show()\n",
    "# fig.write_html('./{}_EntropyAcrossChannels.html'.format(subject_list[subject_idx]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 7. Compute MSE across all subjects in a given group\n",
    "- #### a. Load all data for all subjects in `folder_path` and put in a dictionary object\n",
    "- #### b. Compute MSE for each channel, get the average MSE for each subject, and save the MSE per scale in a df\n",
    "- #### c. Plot the MSE values across each subject and the average across subjects"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Load all data for all subjects in `folder_path` and put in a dictionary object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_dict = {} # initialize an empty dictionary to which each subject's data will be added\n",
    "trimmed_data_length = np.arange(0, 30*sfreq) # define the length of data to trim down to\n",
    "\n",
    "for subject_name in tqdm(subject_list):\n",
    "    dpath = './data/Non_Users/ProcessedData/Filtered_Data/{}_FilteredData.csv'.format(subject_name)\n",
    "    data = pd.read_csv(dpath)\n",
    "    data = data.iloc[:,1:] # remove the first column because that column is the timestamps column\n",
    "\n",
    "    data = data.iloc[trimmed_data_length,:] # trim the data to just the first 30sec\n",
    "\n",
    "    all_data_dict[subject_name] = data # add the current subject's data to the dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Compute MSE for each channel, get the average MSE for each subject, and save the MSE per scale in a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = 20\n",
    "scales_list = np.arange(1, scales+1)\n",
    "chs_to_exclude = ['VEOG', 'HEOG', 'LeftMast', 'RightMast'] # define any channels to exclude\n",
    "\n",
    "# initialize empty dataframes to which the data will be added in the for loop\n",
    "mse_across_subjects_df = pd.DataFrame(columns=['Subject','Scale','Entropy'])\n",
    "ci_across_subjects_df  = pd.DataFrame(columns=['Subject','CI'])\n",
    "\n",
    "for subject_name in tqdm(subject_list):\n",
    "    data = all_data_dict[subject_name]\n",
    "    data = data[[ch not in chs_to_exclude for ch in data.columns]] # exclude any channels that you don't want included\n",
    "\n",
    "    \n",
    "    mean_eeg = data.mean(axis=1).values # compute mean eeg trace\n",
    "    Msx, CI = EntropyHub.MSEn(mean_eeg, Mobj, Scales=scales) # compute entropy across scales and complexity index\n",
    "\n",
    "    # add the current subject's data to the overall dataframes\n",
    "    subject_mse_df = pd.DataFrame({'Subject':subject_name, 'Scale':scales_list, 'Entropy':Msx})\n",
    "    mse_across_subjects_df = mse_across_subjects_df.append(subject_mse_df)\n",
    "    ci_across_subjects_df = ci_across_subjects_df.append(pd.Series({'Subject':subject_name, 'CI':CI}), ignore_index=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Plot the MSE values across each subject and the average across subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# compute mean and standard error across subjects for MSE\n",
    "avg_mse_across_subjects = mse_across_subjects_df.groupby(['Scale']).mean().reset_index()['Entropy'].values\n",
    "sem_mse_across_subjects = mse_across_subjects_df.groupby(['Scale']).sem().reset_index()['Entropy'].values\n",
    "\n",
    "# plot each subject's data\n",
    "for subject_name in mse_across_subjects_df['Subject'].unique():\n",
    "    subject_data = mse_across_subjects_df[mse_across_subjects_df['Subject'] == subject_name]\n",
    "\n",
    "    fig.add_trace(go.Scattergl(x=subject_data['Scale'].values, y=subject_data['Entropy'].values, mode='lines+markers', line=dict(color='slategrey'),\n",
    "                               marker=dict(color='slategrey', size=8), name=subject_name))\n",
    "\n",
    "# add line for average across subjects\n",
    "fig.add_trace(go.Scattergl(x=scales_list, y=avg_mse_across_subjects, error_y=dict(type='data', array=sem_mse_across_subjects, visible=True),\n",
    "                           mode='lines+markers', line=dict(color='black', width=6),\n",
    "                           marker=dict(color='black', size=12), name='Average'))\n",
    "\n",
    "fig.update_layout(template='simple_white', width=1000, height=600, font=dict(size=20),\n",
    "                  xaxis_title='Scales', yaxis_title='Sample Entropy')\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
